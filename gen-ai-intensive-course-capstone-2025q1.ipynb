{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 💼 Resume Reviewer – Job Match Assistant\n\n## 📌1. Project Overview\n\nThis project builds a GenAI-powered assistant that analyzes a resume in the context of a job description and offers actionable feedback. The assistant helps job seekers:\n\n- Understand how well their resume aligns with a job\n- Get specific suggestions for edits and improvements\n- Automatically generate a personalized cover letter\n- View results in a clean JSON format that can be reused or visualized\n\n## 🧠 GenAI Capabilities Demonstrated\n\nThis notebook showcases:\n\n1. **Long-context handling** — process resume and job description together  \n2. **Few-shot prompting** — guide output using examples  \n3. **Structured output (JSON)** — receive parseable, machine-readable results  \n4. **Document understanding** — analyze resumes and JDs  \n5. **Retrieval-Augmented Generation (RAG)** — surface relevant sections  \n6. **Context caching** — avoid repeating work on same inputs\n\n## 🔧 Technologies Used\n\n- Google Gemini API (`google-generativeai`)\n- FAISS for similarity search\n- Joblib for caching\n- Python & Jupyter\n","metadata":{}},{"cell_type":"markdown","source":"## 🟦 2. Imports & Setup\n\nWe will:\n\n- Use only the required libraries for GenAI, RAG, and caching\n- Install Gemini SDK if needed\n- Load secrets using Kaggle's secure interface\n","metadata":{}},{"cell_type":"code","source":"# Remove conflicting JupyterLab packages\n!pip uninstall -qy jupyterlab jupyterlab-lsp\n# Reinstall compatible JupyterLab (ensure version 3.x)\n!pip install -qU 'jupyterlab>=3.1.0,<4.0.0a0'\n!pip install -qU jupyterlab-lsp\n\n# Install Gemini SDK, FAISS for vector search, and PDF parser\n!pip install -qU google-genai==1.7.0 faiss-cpu pdfminer.six\n!pip install PyPDF2 --quiet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T22:44:32.675162Z","iopub.execute_input":"2025-04-20T22:44:32.675377Z","iopub.status.idle":"2025-04-20T22:45:00.743592Z","shell.execute_reply.started":"2025-04-20T22:44:32.675357Z","shell.execute_reply":"2025-04-20T22:45:00.742649Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.7/144.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.9/100.9 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import re\nimport os\nimport numpy as np\nimport pandas as pd\nimport faiss\nfrom pdfminer.high_level import extract_text\nfrom google import genai\nfrom google.genai import types\nfrom urllib.parse import urlparse\nfrom bs4 import BeautifulSoup\nfrom kaggle_secrets import UserSecretsClient\nimport requests, io, json\nfrom pathlib import Path\nfrom PyPDF2 import PdfReader\nfrom collections import OrderedDict\nimport time\nfrom joblib import Memory\nfrom google.genai import types, errors\n\n\n# Load API key\nGOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\nclient = genai.Client(api_key=GOOGLE_API_KEY)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T22:45:00.744849Z","iopub.execute_input":"2025-04-20T22:45:00.745103Z","iopub.status.idle":"2025-04-20T22:45:04.074844Z","shell.execute_reply.started":"2025-04-20T22:45:00.745079Z","shell.execute_reply":"2025-04-20T22:45:04.073597Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"## 🟧 3. Data Upload + Preprocessing\n\n- Upload your resume and job description as Kaggle Dataset inputs\n- Extract and clean text from PDF or TXT files\n- Parse sections like Summary, Skills, Experience, etc.\n- Filter out irrelevant boilerplate from job descriptions\n","metadata":{}},{"cell_type":"code","source":"def extract_sections_by_heading(text: str) -> dict[str,str]:\n    \"\"\"\n    Split `text` at lines that are headings, collecting each heading + its content.\n    A heading is a line in ALL‑CAPS (at least 3 letters) or ending in a colon.\n    \"\"\"\n    lines = text.splitlines()\n    sections = OrderedDict()\n    current = None\n    buf = []\n\n    heading_pattern = re.compile(r\"^([A-Z][A-Z &]{2,}|.+:)$\")\n    for line in lines:\n        if heading_pattern.match(line.strip()):\n            # Save previous\n            if current:\n                sections[current] = \"\\n\".join(buf).strip()\n            # Start new\n            current = line.strip().rstrip(\":\")\n            buf = []\n        else:\n            if current:\n                buf.append(line)\n    # Final flush\n    if current:\n        sections[current] = \"\\n\".join(buf).strip()\n\n    return dict(sections)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T22:45:04.076780Z","iopub.execute_input":"2025-04-20T22:45:04.077251Z","iopub.status.idle":"2025-04-20T22:45:04.085140Z","shell.execute_reply.started":"2025-04-20T22:45:04.077225Z","shell.execute_reply":"2025-04-20T22:45:04.084143Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def fetch_document(source: str, dest_folder: Path) -> Path:\n    \"\"\"\n    1. Google‑Drive share → direct PDF download.\n    2. URL ending in .pdf → download.\n    3. Otherwise → download HTML.\n    Saves under dest_folder; returns local Path.\n    \"\"\"\n    dest_folder.mkdir(parents=True, exist_ok=True)\n\n    if \"drive.google.com/file/d/\" in source:\n        fid     = re.search(r\"/d/([^/]+)\", source).group(1)\n        dl_url  = f\"https://drive.google.com/uc?export=download&id={fid}\"\n        filename= f\"{fid}.pdf\"\n        content = requests.get(dl_url).content\n\n    elif source.lower().endswith(\".pdf\"):\n        filename= Path(urlparse(source).path).name\n        content = requests.get(source).content\n\n    else:\n        parsed = urlparse(source)\n        stem   = Path(parsed.path).stem or \"page\"\n        filename= f\"{stem}.html\"\n        content = requests.get(source).content\n\n    local_path = dest_folder / filename\n    local_path.write_bytes(content)\n    return local_path\n\ndef pdf_to_text(pdf_path: Path) -> str:\n    reader = PdfReader(str(pdf_path))\n    return \"\\n\".join(p.extract_text() or \"\" for p in reader.pages)\n\ndef html_to_text(html_path: Path) -> str:\n    raw = html_path.read_text(encoding=\"utf8\")\n    return BeautifulSoup(raw, \"html.parser\").get_text(separator=\"\\n\")\n\ndef load_and_parse(source: str, workdir: Path) -> str:\n    p = fetch_document(source, workdir)\n    if p.suffix.lower() == \".pdf\":\n        return pdf_to_text(p)\n    elif p.suffix.lower() in (\".html\",\"htm\"):\n        return html_to_text(p)\n    else:\n        return p.read_text()\n\n# # — Ask user for sources —\n# resume_src = input(\"Resume URL or Kaggle-input path: \").strip()\n# jd_src     = input(\"Job    URL or Kaggle-input path: \").strip()\n\n\nresume_src = \"https://drive.google.com/file/d/1u373zWQWxZWD9yAcnFtw2nmcy62b2ULr/view?usp=sharing\"\njd_src     = \"https://amazon.jobs/en-gb/jobs/2772291/2025-software-dev-engineer-intern-uk\"\n\n\n\nworkdir    = Path(\"/kaggle/working/docs\")\nresume_text= load_and_parse(resume_src, workdir)\njd_text    = load_and_parse(jd_src,    workdir)\n\n# — (Optional) Section extraction —\ndef extract_sections(text: str) -> dict[str,str]:\n    # Try named‑section regex first\n    named = {}\n    for hdr in [\"Summary\",\"Experience\",\"Skills\",\"Education\"]:\n        pat = rf\"{hdr}[:\\n](.*?)(?=\\n[A-Z][a-z]+:|\\Z)\"\n        m = re.search(pat, text, re.DOTALL)\n        named[hdr] = m.group(1).strip() if m else \"\"\n\n    # If none found, do heading-driven split\n    if all(not v for v in named.values()):\n        return extract_sections_by_heading(text)\n\n    return {k:v for k,v in named.items() if v}\n\n# Then:\nresume_secs = extract_sections(resume_text)\nif not resume_secs:\n    resume_chunks = [resume_text]\nelse:\n    resume_chunks = list(resume_secs.values())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T22:45:04.086168Z","iopub.execute_input":"2025-04-20T22:45:04.086524Z","iopub.status.idle":"2025-04-20T22:45:07.401483Z","shell.execute_reply.started":"2025-04-20T22:45:04.086498Z","shell.execute_reply":"2025-04-20T22:45:07.400550Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"print(resume_secs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T22:45:07.402307Z","iopub.execute_input":"2025-04-20T22:45:07.402647Z","iopub.status.idle":"2025-04-20T22:45:07.408310Z","shell.execute_reply.started":"2025-04-20T22:45:07.402624Z","shell.execute_reply":"2025-04-20T22:45:07.407154Z"}},"outputs":[{"name":"stdout","text":"{'SIDDHARTH SHARMA': '+44 7407841707 ⋄U.K.\\ns1ddh9rth@gmail.com ⋄LinkedIn ⋄GitHub ⋄Leetcode', 'SUMMARY': 'Aspiring AI/ML Engineer with a Master’s degree from Aston University, specializing in Machine Learning. Proficient\\nin Python, with experience in designing and training AI models using PyTorch, Scikit-learn and TensorFlow .\\nPassionate about applying advanced algorithms to solve real-world problems and leveraging AI to drive innovation.', 'EDUCATION': 'M.Sc. Artificial Intelligence , Aston University, U.K. Sept 2023 - Oct 2024\\nRelevant Coursework: Machine Learning, Deep Learning, Data Mining, Multi Agent Systems, Robotics and Mathe-\\nmatics for AI.\\nDissertation: Enhancing Multi-Limb Coordination for Humanoid Robots using Reinforcement Learning.\\nB.Sc. Computer Application , Aligarh Muslim University, IN Aug 2017 - Oct 2020', 'TECHNICAL SKILLS': '•Proficient: Machine Learning Algorithms, Reinforcement Learning, Data Structures and Algorithms, Docker,\\nLarge-Language Models , CI/CD, Pyspark, RESTful API s.\\n•Familiar: AWS (SageMaker, Glue, S3, Redshift, Athena), Robotics, Deep Learning, Terraform, NLP\\n•Programming: Python , C++, JavaScript, R, Git.', 'WORK EXPERIENCE': 'AI And ML Intern Aug 2024 - Oct 2024\\nYBi Foundation |(Link to Github) Remote\\n•Developed 3 Dockerized PySpark pipelines , achieving 90%+ accuracy in predictive models for churn, pref-\\nerences, and recommendations using Naive Bayes and SVC.\\n•Optimized classification and regression models, reducing data imbalance effects by 20% through advanced\\npreprocessing techniques.\\n•Utilized machine learning libraries such as scikit-learn, PyTorch, TensorFlow, and Keras to enhance the\\nperformance and predictive accuracy of supervised and unsupervised algorithms and models .', 'PROJECTS': 'Enhancing Multi Limb Coordination for Humanoid Robots using RL May 2024 - Sept 2024\\nDissertation - Aston University |(Link to Github) Birmingham, U.K.\\n•Analyzed 5+dyno movement challenges for humanoid robots using reinforcement learning in Python .\\n•Engineered advanced reward functions, improving humanoid agility and multi limb coordination by 20% in\\nsimulation training.\\n•Employed Gymnasium and PyBullet with PPO algorithm for effective simulation and training.', 'CERTIFICATIONS': '•First place in Severn Trent Wavemakers Program, Aston University\\n•CodeKaze, Coding Ninjas\\n•Mastering Data Structures and Algorithms using C and C++, Udemy\\n•The Ultimate MySQL Bootcamp, Udemy'}\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"jd_secs = extract_sections(jd_text)\nif not jd_secs:\n    jd_chunks = [jd_text]\nelse:\n    jd_chunks = list(jd_secs.values())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T22:45:07.409277Z","iopub.execute_input":"2025-04-20T22:45:07.409621Z","iopub.status.idle":"2025-04-20T22:45:07.476140Z","shell.execute_reply.started":"2025-04-20T22:45:07.409591Z","shell.execute_reply":"2025-04-20T22:45:07.474892Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"print(jd_secs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T22:45:07.477513Z","iopub.execute_input":"2025-04-20T22:45:07.477785Z","iopub.status.idle":"2025-04-20T22:45:07.497076Z","shell.execute_reply.started":"2025-04-20T22:45:07.477766Z","shell.execute_reply":"2025-04-20T22:45:07.496053Z"}},"outputs":[{"name":"stdout","text":"{'FAQ': 'Interview tips\\nReview application status\\nProvisions for disabled candidates\\nLegal disclosures and notices\\n Amazon is an Equal Opportunity Employer – Minority / Women / Disability / Veteran / Gender Identity / Sexual Orientation / Age.\\nPrivacy and Data\\nCompany Information\\n© 1996-2025, Amazon.com, Inc. or its affiliates', 'DESCRIPTION': 'Do you want to solve business challenges through innovative technology? Do you enjoy working on cutting-edge, scalable services technology in a team environment? Do you like working on industry-defining projects that move the needle? \\nAt Amazon, we hire the best minds in technology to innovate and build on behalf of our customers. The intense focus we have on our customers is why we are one of the world’s most beloved brands – customer obsession is part of our company DNA. Our interns write real software and collaborate with a selected group of experienced software development engineers who help interns on projects that matter to our customers. \\nWe want to you to feel welcomed, included and valued right from the start. Every day will be filled with exciting new challenges, developing new skills, and achieving personal growth. How often can you say that your work changes the world? At Amazon, you’ll say it often. Join us and define tomorrow.', 'We have two different internship durations available': '- 3 months internship\\n- 6 months internship\\nPlease ensure to indicate your availability during the application process. \\nKey job responsibilities\\n- Collaborate with experienced cross-disciplinary Amazonians to conceive, design, and bring to market innovative products and services.\\n- Design and build innovative technologies in a large distributed computing environment and help lead fundamental changes in the industry.\\n- Create solutions to run predictions on distributed systems with exposure to innovative technologies at incredible scale and speed.\\n- Build distributed storage, index, and query systems that are scalable, fault-tolerant, low cost, and easy to manage/use.\\n- Work in an agile environment to deliver high quality software.\\nA day in the life\\nAs an intern, you will be matched to a manager and a mentor. You will have the opportunity to influence the evolution of Amazon technology and lead mission critical projects early in your career. Your design, code, and raw smarts will contribute to solving some of the most complex technical challenges in the areas of distributed systems, data mining, automation, optimisation, scalability, and security – just to name a few.\\nIn addition to working on an impactful project, you will have the opportunity to engage with Amazonians for both personal and professional development, expand your network, and participate in activities with other interns throughout your internship. No matter the location of your internship, we give you the tools to own your project and learn in a real-world setting. Many of our technologies overlap, and you would be hard pressed to find a team that is not using Amazon Web Services (AWS), touching the catalogue, or iterating services to better personalise for customers.  We make the impossible, possible.', 'BASIC QUALIFICATIONS': '- Currently enrolled in a Bachelor’s or Master’s Degree in Computer Science, Computer Engineering, or related fields at time of application\\n- Although no specific programming language is required – you should be familiar with the syntax of languages such as Java, C/C++, or Python\\n- Knowledge of Computer Science fundamentals such as object-oriented design, algorithm design, data structures, problem solving and complexity analysis', 'PREFERRED QUALIFICATIONS': '- Previous technical internship(s) if applicable\\n- Experience with distributed, multi-tiered systems, algorithms, and relational databases\\n- Experience in optimization mathematics such as linear programming and nonlinear optimisation\\n- Ability to effectively articulate technical challenges and solutions\\n- Adept at handling ambiguous or undefined problems as well as ability to think abstractly\\nAmazon is an equal opportunities employer. We believe passionately that employing a diverse workforce is central to our success. We make recruiting decisions based on your experience and skills. We value your passion to discover, invent, simplify and build. Protecting your privacy and the security of your data is a longstanding top priority for Amazon. Please consult our Privacy Notice (https://www.amazon.jobs/en/privacy_page) to know more about how we collect, use and transfer the personal data of our candidates.\\nAmazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/content/en/how-we-hire/accommodations.\\nJob details\\nGBR, London\\nGBR, Cambridge\\nGBR, Edinburgh\\nInternships for students\\nSoftware Development\\nShare this job', 'JOIN US ON': 'Find Careers\\nJob Categories\\nTeams\\nLocations\\nMilitary recruiting\\nWarehouse and Hourly Jobs\\nWorking at Amazon\\nCulture\\nBenefits\\nAmazon Newsletter\\nDiversity at Amazon\\nOur Leadership Principles\\nHelp'}\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"## 🟨 4. Context Caching Logic\n\nTo save time and quota, we cache:\n\n- Extracted resume text\n- Extracted JD text\n- Embeddings of both\n\nThis ensures we don’t re-embed or re-parse the same files.\n","metadata":{}},{"cell_type":"code","source":"cache = Memory(location=\"/kaggle/working/.cache\", verbose=0)\n\n@cache.cache\ndef embed_texts(texts: list[str]) -> np.ndarray:\n    for attempt in range(5):\n        try:\n            resp = client.models.embed_content(\n                model    = \"models/text-embedding-004\",\n                contents = texts,\n                config   = types.EmbedContentConfig(task_type=\"semantic_similarity\")\n            )\n            # <-- use .values, not .embedding\n            vectors = [e.values for e in resp.embeddings]\n            return np.stack(vectors).astype(np.float32)\n\n        except errors.ClientError as e:\n            if e.status == 429 and attempt < 4:\n                wait = 2 ** attempt\n                print(f\"Rate‑limited; retrying in {wait}s…\")\n                time.sleep(wait)\n            else:\n                raise\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T22:45:07.498168Z","iopub.execute_input":"2025-04-20T22:45:07.498454Z","iopub.status.idle":"2025-04-20T22:45:07.519964Z","shell.execute_reply.started":"2025-04-20T22:45:07.498426Z","shell.execute_reply":"2025-04-20T22:45:07.518894Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"resume_embs   = embed_texts(resume_chunks)\nprint(\"Embeddings shape:\", resume_embs.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T22:45:07.522426Z","iopub.execute_input":"2025-04-20T22:45:07.523146Z","iopub.status.idle":"2025-04-20T22:45:08.007397Z","shell.execute_reply.started":"2025-04-20T22:45:07.523116Z","shell.execute_reply":"2025-04-20T22:45:08.006342Z"}},"outputs":[{"name":"stdout","text":"Embeddings shape: (7, 768)\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"jd_embs = embed_texts(jd_chunks)\nprint(\"JD embeddings shape:\", jd_embs.shape) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T22:45:08.008321Z","iopub.execute_input":"2025-04-20T22:45:08.008606Z","iopub.status.idle":"2025-04-20T22:45:08.213287Z","shell.execute_reply.started":"2025-04-20T22:45:08.008587Z","shell.execute_reply":"2025-04-20T22:45:08.212487Z"}},"outputs":[{"name":"stdout","text":"JD embeddings shape: (6, 768)\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"## 🟪 5. RAG: Retrieval-Augmented Generation\n\n- We create FAISS indexes for both resume and JD embeddings\n- When a user asks a question (e.g., \"what can I improve?\"), we:\n  - Embed the query\n  - Find the most relevant sections from resume + JD\n  - Pass those chunks into the prompting pipeline\n","metadata":{}},{"cell_type":"code","source":"d     = resume_embs.shape[1]\nindex = faiss.IndexFlatIP(d)\nfaiss.normalize_L2(resume_embs)\nindex.add(resume_embs)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T22:45:08.214421Z","iopub.execute_input":"2025-04-20T22:45:08.214727Z","iopub.status.idle":"2025-04-20T22:45:08.219302Z","shell.execute_reply.started":"2025-04-20T22:45:08.214707Z","shell.execute_reply":"2025-04-20T22:45:08.218348Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"d_j = resume_embs.shape[1]  \n\nindex_jd = faiss.IndexFlatIP(d_j)\nfaiss.normalize_L2(jd_embs)\nindex_jd.add(jd_embs)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T22:45:08.220376Z","iopub.execute_input":"2025-04-20T22:45:08.220868Z","iopub.status.idle":"2025-04-20T22:45:08.237693Z","shell.execute_reply.started":"2025-04-20T22:45:08.220831Z","shell.execute_reply":"2025-04-20T22:45:08.236641Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def retrieve_resume_and_jd(query: str, k: int = 3):\n    q_emb = embed_texts([query])\n    faiss.normalize_L2(q_emb)\n\n    # Resume hits\n    Dr, Ir = index.search(q_emb, k)\n    resume_hits = [\n        (\"resume\", resume_chunks[i], float(Dr[0,j]))\n        for j,i in enumerate(Ir[0])\n    ]\n\n    # JD hits\n    Dj, Ij = index_jd.search(q_emb, k)\n    jd_hits = [\n        (\"jd\", jd_chunks[i], float(Dj[0,j]))\n        for j,i in enumerate(Ij[0])\n    ]\n\n    # Combine & pick top‑k overall\n    all_hits = resume_hits + jd_hits\n    all_hits.sort(key=lambda x: x[2], reverse=True)\n    return all_hits[:k]\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T22:45:08.238649Z","iopub.execute_input":"2025-04-20T22:45:08.238957Z","iopub.status.idle":"2025-04-20T22:45:08.258675Z","shell.execute_reply.started":"2025-04-20T22:45:08.238936Z","shell.execute_reply":"2025-04-20T22:45:08.257723Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"hits = retrieve_resume_and_jd(\"what skills match this role?\")\nfor src, txt, score in hits:\n    print(f\"[{src.upper()} • {score:.3f}]\\n{txt}\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T22:45:08.259780Z","iopub.execute_input":"2025-04-20T22:45:08.260107Z","iopub.status.idle":"2025-04-20T22:45:08.466911Z","shell.execute_reply.started":"2025-04-20T22:45:08.260077Z","shell.execute_reply":"2025-04-20T22:45:08.465819Z"}},"outputs":[{"name":"stdout","text":"[JD • 0.649]\n- Previous technical internship(s) if applicable\n- Experience with distributed, multi-tiered systems, algorithms, and relational databases\n- Experience in optimization mathematics such as linear programming and nonlinear optimisation\n- Ability to effectively articulate technical challenges and solutions\n- Adept at handling ambiguous or undefined problems as well as ability to think abstractly\nAmazon is an equal opportunities employer. We believe passionately that employing a diverse workforce is central to our success. We make recruiting decisions based on your experience and skills. We value your passion to discover, invent, simplify and build. Protecting your privacy and the security of your data is a longstanding top priority for Amazon. Please consult our Privacy Notice (https://www.amazon.jobs/en/privacy_page) to know more about how we collect, use and transfer the personal data of our candidates.\nAmazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/content/en/how-we-hire/accommodations.\nJob details\nGBR, London\nGBR, Cambridge\nGBR, Edinburgh\nInternships for students\nSoftware Development\nShare this job\n\n[JD • 0.628]\n- Currently enrolled in a Bachelor’s or Master’s Degree in Computer Science, Computer Engineering, or related fields at time of application\n- Although no specific programming language is required – you should be familiar with the syntax of languages such as Java, C/C++, or Python\n- Knowledge of Computer Science fundamentals such as object-oriented design, algorithm design, data structures, problem solving and complexity analysis\n\n[RESUME • 0.620]\n•Proficient: Machine Learning Algorithms, Reinforcement Learning, Data Structures and Algorithms, Docker,\nLarge-Language Models , CI/CD, Pyspark, RESTful API s.\n•Familiar: AWS (SageMaker, Glue, S3, Redshift, Athena), Robotics, Deep Learning, Terraform, NLP\n•Programming: Python , C++, JavaScript, R, Git.\n\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"## 🟫 6. Few-shot Prompting\n\nWe guide the model with curated examples for:\n\n- Suggested edits (before/after changes)\n- Cover letter structure and phrasing\n\nThese examples help the model understand the desired format and tone.\n","metadata":{}},{"cell_type":"code","source":"edit_examples = [\n  {\n    \"before\": \"Led team of analysts\",\n    \"after\":  \"Led a team of 5 analysts to deliver 20% efficiency gains\"\n  },\n]\n\ncover_examples = [\n  {\n    \"role\":    \"Data Analyst\",\n    \"opening\": \"Dear Hiring Manager at ${COMPANY},\\nI’m excited to apply because…\",\n    \"closing\": \"Thank you for your time and consideration.\\nSincerely,\\n${YOUR_NAME}\"\n  },\n]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T22:45:08.467884Z","iopub.execute_input":"2025-04-20T22:45:08.468133Z","iopub.status.idle":"2025-04-20T22:45:08.473247Z","shell.execute_reply.started":"2025-04-20T22:45:08.468113Z","shell.execute_reply":"2025-04-20T22:45:08.472109Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"print(edit_examples)\nprint(cover_examples)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T22:45:08.474301Z","iopub.execute_input":"2025-04-20T22:45:08.474684Z","iopub.status.idle":"2025-04-20T22:45:08.491532Z","shell.execute_reply.started":"2025-04-20T22:45:08.474655Z","shell.execute_reply":"2025-04-20T22:45:08.490685Z"}},"outputs":[{"name":"stdout","text":"[{'before': 'Led team of analysts', 'after': 'Led a team of 5 analysts to deliver 20% efficiency gains'}]\n[{'role': 'Data Analyst', 'opening': 'Dear Hiring Manager at ${COMPANY},\\nI’m excited to apply because…', 'closing': 'Thank you for your time and consideration.\\nSincerely,\\n${YOUR_NAME}'}]\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"## 🟩 7. Structured Output (JSON)\n\nThe final result is a structured JSON containing:\n\n```json\n{\n  \"match_score\": 87,\n  \"suggestions\": [\n    {\"section\": \"Summary\", \"action\": \"Add quantifiable metrics\"},\n    ...\n  ],\n  \"cover_letter\": \"Dear Hiring Manager...\"\n}\n","metadata":{}},{"cell_type":"code","source":"user_q = \"How well does my resume match the job description?\"\ntop_hits     = retrieve_resume_and_jd(user_q, k=5)\nscores       = [score for _,_,score in top_hits]\nmatch_score  = sum(scores) / len(scores)\nrag_contexts = [txt for _,txt,_ in top_hits]\n\n# --- 2) Build the payload, including our pre‑computed match_score ---\npayload = {\n  \"match_score\":      match_score,\n  \"resume\":           resume_secs,\n  \"job_description\":  jd_secs,\n  \"user_question\":    user_q,\n  \"rag_contexts\":     rag_contexts,\n  \"examples\": {\n    \"edits\": edit_examples,\n    \"cover\": cover_examples\n  }\n}\n\n# --- 3) Strict system prompt (no markdown, must echo match_score) ---\nsystem_prompt = \"\"\"\nYou will receive a JSON payload.\nYour job is to OUTPUT EXACTLY one valid JSON object with keys:\n1) match_score  – use the provided number.\n2) suggestions  – a LIST of {section,action} objects.\n3) cover_letter – a SINGLE escaped string.\n\nThe cover_letter must:\n- Be at least 200 words long.\n- Be formatted as a professional letter: opening paragraph, 2 body paragraphs, closing paragraph.\n- Use '\\\\n' for all line breaks.\n- NOT include any markdown or code fences.\n\nDo NOT output any extra keys or nested objects—only raw JSON.\n\"\"\".strip()\n\n\ncontents = [\n    system_prompt,\n    json.dumps(payload, separators=(\",\",\":\"))\n]\n\nanswer = client.models.generate_content(\n    model    = \"gemini-2.0-flash\",\n    contents = contents,\n    config   = types.GenerateContentConfig(temperature=0.2)\n)\n\nraw = answer.text.strip()\nm = re.search(r\"(\\{.*\\})\", raw, flags=re.DOTALL)\nif not m:\n    raise ValueError(f\"No JSON found in model output:\\n{raw}\")\njson_str = m.group(1)\n\nresult = json.loads(json_str)\nprint(f\"🎯 Match score: {result['match_score']:.2f}\\n\\n📌 Suggestions:\")\nfor s in result[\"suggestions\"]:\n    print(f\" - [{s['section']}] {s['action']}\")\nprint(\"\\n✉️ Cover Letter:\\n\")\nprint(result[\"cover_letter\"].replace(\"\\\\n\",\"\\n\"))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T22:46:04.119029Z","iopub.execute_input":"2025-04-20T22:46:04.119390Z","iopub.status.idle":"2025-04-20T22:46:07.339938Z","shell.execute_reply.started":"2025-04-20T22:46:04.119365Z","shell.execute_reply":"2025-04-20T22:46:07.339092Z"}},"outputs":[{"name":"stdout","text":"🎯 Match score: 0.58\n\n📌 Suggestions:\n - [TECHNICAL SKILLS] Prioritize skills mentioned in the job description, such as experience with distributed systems and relational databases.\n - [WORK EXPERIENCE] Quantify achievements and align them with the responsibilities outlined in the job description.\n - [PROJECTS] Highlight projects that demonstrate experience with relevant technologies and problem-solving skills.\n\n✉️ Cover Letter:\n\nDear Amazon Hiring Team,\n\nI am writing to express my keen interest in the Software Development Intern position at Amazon, as advertised on your careers page. With a Master's degree in Artificial Intelligence and a strong foundation in computer science principles, I am confident that my skills and experience align well with the requirements outlined in the job description. My passion for leveraging technology to solve complex business challenges, coupled with my hands-on experience in developing and deploying machine learning models, makes me a strong candidate for this internship.\n\nDuring my AI and ML internship at YBi Foundation, I developed and optimized PySpark pipelines, achieving significant improvements in predictive model accuracy. I also have experience with various machine learning libraries, including scikit-learn, PyTorch, and TensorFlow, which I utilized to enhance the performance of supervised and unsupervised algorithms. Furthermore, my dissertation focused on enhancing multi-limb coordination for humanoid robots using reinforcement learning, demonstrating my ability to tackle challenging problems in the field of robotics and AI. I am proficient in Python, C++, JavaScript, and R, and I am familiar with AWS services such as SageMaker, Glue, and S3.\n\nI am particularly drawn to Amazon's commitment to innovation and its customer-centric approach. I am eager to contribute to a team that is dedicated to building cutting-edge technologies and solving real-world problems at scale. I am a quick learner, a collaborative team player, and I am confident that I can make a meaningful contribution to Amazon during my internship. Thank you for considering my application. I have attached my resume for your review and welcome the opportunity to discuss my qualifications further.\n\nSincerely,\nSiddharth Sharma\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}